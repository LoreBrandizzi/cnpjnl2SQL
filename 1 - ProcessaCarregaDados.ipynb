{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fde7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "from pyspark.sql.functions import to_date, when\n",
    "from pyspark.sql.functions import regexp_replace, col\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15574b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"CNPJ\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec5125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar a sessão Spark\n",
    "\n",
    "#spark = SparkSession.builder \\\n",
    "#    .appName(\"CNPJ\") \\\n",
    "#    .config(\"spark.executor.memory\", \"6g\") \\\n",
    "#    .config(\"spark.executor.cores\", \"1\") \\\n",
    "#    .config(\"spark.executor.instances\", \"6\") \\\n",
    "#    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "#    .config(\"spark.yarn.am.memory\", \"2g\") \\\n",
    "#    .config(\"spark.network.timeout\", \"600s\") \\\n",
    "#    .config(\"spark.executor.heartbeatInterval\", \"100s\") \\\n",
    "#    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "#    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afee8027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefixo do caminho para os arquivos CSV no bucket do Google Cloud Storage\n",
    "prefix = \"gs://dataproc-staging-us-central1-574457499229-8awbbdyx/notebooks/jupyter/DADOS/K3241.\"\n",
    "suffix_empresas = \".D40608.EMPRECSV\"\n",
    "suffix_socios = \".D40608.SOCIOCSV\"\n",
    "suffix_estabele = \".D40608.ESTABELE\"\n",
    "\n",
    "# Lista para armazenar os nomes dos arquivos de cada tipo\n",
    "file_paths_empresas = []\n",
    "file_paths_socios = []\n",
    "file_paths_estabele = []\n",
    "\n",
    "# Gerar os caminhos para os arquivos CSV de EMPRESAS\n",
    "for i in range(10):\n",
    "    file_name_empresas = f\"{prefix}K03200Y{i}{suffix_empresas}\"\n",
    "    file_paths_empresas.append(file_name_empresas)\n",
    "\n",
    "# Gerar os caminhos para os arquivos CSV de SOCIOS\n",
    "for i in range(10):\n",
    "    file_name_socios = f\"{prefix}K03200Y{i}{suffix_socios}\"\n",
    "    file_paths_socios.append(file_name_socios)\n",
    "\n",
    "# Gerar os caminhos para os arquivos CSV de ESTABELE\n",
    "for i in range(10):\n",
    "    file_name_estabele = f\"{prefix}K03200Y{i}{suffix_estabele}\"\n",
    "    file_paths_estabele.append(file_name_estabele)\n",
    "\n",
    "# Imprimir os caminhos dos arquivos\n",
    "print(\"EMPRESAS:\")\n",
    "for path in file_paths_empresas:\n",
    "    print(path)\n",
    "\n",
    "print(\"\\nSOCIOS:\")\n",
    "for path in file_paths_socios:\n",
    "    print(path)\n",
    "\n",
    "print(\"\\nESTABELE:\")\n",
    "for path in file_paths_estabele:\n",
    "    print(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9649714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTAR múltiplos arquivos CSV de empresas com um esquema definido, \n",
    "# unindo-os em um único DataFrame e criando uma view temporária chamada \"EMPRESAS\" no Spark.\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"CNPJBASICO\", StringType(), True),\n",
    "    StructField(\"RAZAOSOCIAL\", StringType(), True),\n",
    "    StructField(\"NATUREZAJURIDICA\", StringType(), True),\n",
    "    StructField(\"QUALIFICACAODORESPONSAVEL\", StringType(), True),\n",
    "    StructField(\"CAPITALSOCIAL\", StringType(), True),\n",
    "    StructField(\"PORTE\", StringType(), True),\n",
    "    StructField(\"ENTEFEDERATIVO\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Ler e unir todos os arquivos CSV em um DataFrame\n",
    "df_list = [spark.read.csv(file_path, header=False, schema=schema, sep=';') for file_path in file_paths_empresas]\n",
    "df = df_list[0]\n",
    "for df_part in df_list[1:]:\n",
    "    df = df.union(df_part)\n",
    "    \n",
    "df = df.withColumn(\"CAPITALSOCIAL\", regexp_replace(col(\"CAPITALSOCIAL\"), \",\", \".\").cast(DoubleType()))\n",
    "# Traduzir valores do porte da empresa\n",
    "df = df.withColumn(\"PORTE\", when(col(\"PORTE\") == '00', 'NÃO INFORMADO')\n",
    "                             .when(col(\"PORTE\") == '01', 'MICRO EMPRESA')\n",
    "                             .when(col(\"PORTE\") == '03', 'EMPRESA DE PEQUENO PORTE')\n",
    "                             .when(col(\"PORTE\") == '05', 'DEMAIS')\n",
    "                             .otherwise('NÃO INFORMADO'))\n",
    "\n",
    "# Criar uma view temporária\n",
    "df.createOrReplaceTempView(\"EMPRESAS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729fdf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTAR múltiplos arquivos CSV de ESTABELECIMENTOS com um esquema definido, \n",
    "# unindo-os em um único DataFrame e criando uma view temporária chamada \"ESTABELECIMENTOS\" no Spark.\n",
    "\n",
    "schema_estabele = StructType([\n",
    "    StructField(\"CNPJBASICO\", StringType(), True),\n",
    "    StructField(\"CNPJORDEM\", StringType(), True),\n",
    "    StructField(\"CNPJDV\", StringType(), True),\n",
    "    StructField(\"IDENTIFICADORMATRIZFILIAL\", StringType(), True),\n",
    "    StructField(\"NOMEFANTASIA\", StringType(), True),\n",
    "    StructField(\"SITUACAOCADASTRAL\", StringType(), True),\n",
    "    StructField(\"DATASITUACAOCADASTRAL\", StringType(), True),\n",
    "    StructField(\"MOTIVOSITUACAOCADASTRAL\", StringType(), True),\n",
    "    StructField(\"NOMECIDADEEXTERIOR\", StringType(), True),\n",
    "    StructField(\"PAIS\", StringType(), True),\n",
    "    StructField(\"DATAINICIOATIVIDADE\", StringType(), True),\n",
    "    StructField(\"CNAEFISCALPRINCIPAL\", StringType(), True),\n",
    "    StructField(\"CNAEFISCALSECUNDARIA\", StringType(), True),\n",
    "    StructField(\"TIPOLOGRADOURO\", StringType(), True),\n",
    "    StructField(\"LOGRADOURO\", StringType(), True),\n",
    "    StructField(\"NUMERO\", StringType(), True),\n",
    "    StructField(\"COMPLEMENTO\", StringType(), True),\n",
    "    StructField(\"BAIRRO\", StringType(), True),\n",
    "    StructField(\"CEP\", StringType(), True),\n",
    "    StructField(\"UF\", StringType(), True),\n",
    "    StructField(\"MUNICIPIO\", StringType(), True),\n",
    "    StructField(\"DDD1\", StringType(), True),\n",
    "    StructField(\"TELEFONE1\", StringType(), True),\n",
    "    StructField(\"DDD2\", StringType(), True),\n",
    "    StructField(\"TELEFONE2\", StringType(), True),\n",
    "    StructField(\"DDDFAX\", StringType(), True),\n",
    "    StructField(\"FAX\", StringType(), True),\n",
    "    StructField(\"EMAIL\", StringType(), True),\n",
    "    StructField(\"SITUACAOESPECIAL\", StringType(), True),\n",
    "    StructField(\"DATASITUACAOESPECIAL\", StringType(), True),\n",
    "])\n",
    "\n",
    "# Ler e unir todos os arquivos CSV de ESTABELECIMENTOS em um DataFrame\n",
    "df_list_estabele = [spark.read.csv(file_path, header=False, schema=schema_estabele, sep=';') for file_path in file_paths_estabele]\n",
    "df_estabele = df_list_estabele[0]\n",
    "for df_part in df_list_estabele[1:]:\n",
    "    df_estabele = df_estabele.union(df_part)\n",
    "    \n",
    "# Transformar campos de data\n",
    "df_estabele = df_estabele.withColumn(\"DATASITUACAOCADASTRAL\", to_date(df_estabele[\"DATASITUACAOCADASTRAL\"], \"yyyyMMdd\"))\n",
    "df_estabele = df_estabele.withColumn(\"DATAINICIOATIVIDADE\", to_date(df_estabele[\"DATAINICIOATIVIDADE\"], \"yyyyMMdd\"))\n",
    "df_estabele = df_estabele.withColumn(\"DATASITUACAOESPECIAL\", to_date(df_estabele[\"DATASITUACAOESPECIAL\"], \"yyyyMMdd\"))\n",
    "# Traduzir valores do identificador matriz/filial\n",
    "df_estabele = df_estabele.withColumn(\"IDENTIFICADORMATRIZFILIAL\", \n",
    "                                     when(col(\"IDENTIFICADORMATRIZFILIAL\") == '1', 'MATRIZ')\n",
    "                                     .when(col(\"IDENTIFICADORMATRIZFILIAL\") == '2', 'FILIAL')\n",
    "                                     .otherwise('NÃO INFORMADO'))\n",
    "\n",
    "# Traduzir valores da situação cadastral\n",
    "df_estabele = df_estabele.withColumn(\"SITUACAOCADASTRAL\", \n",
    "                                     when(col(\"SITUACAOCADASTRAL\") == '01', 'NULA')\n",
    "                                     .when(col(\"SITUACAOCADASTRAL\") == '02', 'ATIVA')\n",
    "                                     .when(col(\"SITUACAOCADASTRAL\") == '03', 'SUSPENSA')\n",
    "                                     .when(col(\"SITUACAOCADASTRAL\") == '04', 'INAPTA')\n",
    "                                     .when(col(\"SITUACAOCADASTRAL\") == '08', 'BAIXADA')\n",
    "                                     .otherwise('NÃO INFORMADO'))\n",
    "\n",
    "\n",
    "\n",
    "# Eliminar o caractere '\\' em NUMERO e COMPLEMENTO\n",
    "df_estabele = df_estabele.withColumn(\"NUMERO\", regexp_replace(col(\"NUMERO\"), r'\\\\', ''))\n",
    "df_estabele = df_estabele.withColumn(\"COMPLEMENTO\", regexp_replace(col(\"COMPLEMENTO\"), r'\\\\', ''))\n",
    "df_estabele = df_estabele.withColumn(\"LOGRADOURO\", regexp_replace(col(\"LOGRADOURO\"), r'\\\\', ''))\n",
    "df_estabele = df_estabele.withColumn(\"LOGRADOURO\", regexp_replace(col(\"LOGRADOURO\"), r'\\\\x00', ''))\n",
    "\n",
    "\n",
    "# Criar uma view temporária\n",
    "df_estabele.createOrReplaceTempView(\"ESTABELECIMENTOS\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f6a3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTAR múltiplos arquivos CSV de socioS com um esquema definido, \n",
    "# unindo-os em um único DataFrame e criando uma view temporária chamada \"SÓCIOS\" no Spark.\n",
    "\n",
    "schema_socios = StructType([\n",
    "    StructField(\"CNPJBASICO\", StringType(), True),\n",
    "    StructField(\"IDENTIFICADORSOCIO\", StringType(), True),\n",
    "    StructField(\"NOMESOCIORAZAOSOCIAL\", StringType(), True),\n",
    "    StructField(\"CNPJCPFSOCIO\", StringType(), True),\n",
    "    StructField(\"QUALIFICACAOSOCIO\", StringType(), True),\n",
    "    StructField(\"DATAENTRADASOCIEDADE\", StringType(), True),\n",
    "    StructField(\"PAIS\", StringType(), True),\n",
    "    StructField(\"CPFREPRESENTANTE\", StringType(), True),\n",
    "    StructField(\"NOMEREPRESENTANTE\", StringType(), True),\n",
    "    StructField(\"QUALIFICACAOREPRESENTANTE\", StringType(), True),\n",
    "    StructField(\"FAIXAETARIA\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Ler e unir todos os arquivos CSV de SOCIOS em um DataFrame\n",
    "df_list_socios = [spark.read.csv(file_path, header=False, schema=schema_socios, sep=';') for file_path in file_paths_socios]\n",
    "df_socios = df_list_socios[0]\n",
    "for df_part in df_list_socios[1:]:\n",
    "    df_socios = df_socios.union(df_part)\n",
    "    \n",
    "# Transformar campos de data\n",
    "df_socios = df_socios.withColumn(\"DATAENTRADASOCIEDADE\", to_date(df_socios[\"DATAENTRADASOCIEDADE\"], \"yyyyMMdd\"))\n",
    "# Traduzir valores do identificador de sócio\n",
    "df_socios = df_socios.withColumn(\"IDENTIFICADORSOCIO\", \n",
    "                                 when(col(\"IDENTIFICADORSOCIO\") == '1', 'PESSOA JURÍDICA')\n",
    "                                 .when(col(\"IDENTIFICADORSOCIO\") == '2', 'PESSOA FÍSICA')\n",
    "                                 .when(col(\"IDENTIFICADORSOCIO\") == '3', 'ESTRANGEIRO')\n",
    "                                 .otherwise('NÃO INFORMADO'))\n",
    "\n",
    "\n",
    "# Traduzir valores do identificador de sócio\n",
    "# Atualizar a coluna \"PAIS\" para 'BRASIL' onde estiver nula ou vazia\n",
    "df_socios = df_socios.withColumn(\n",
    "    \"PAIS\", \n",
    "    when((col(\"PAIS\") == '') | col(\"PAIS\").isNull() | (col(\"PAIS\") =='NULL'), 'BRASIL')\n",
    "    .otherwise(col(\"PAIS\"))\n",
    ")\n",
    "\n",
    "\n",
    "df_socios = df_socios.withColumn(\"FAIXAETARIA\", \n",
    "                                 when(col(\"FAIXAETARIA\") == '0', '0-12')\n",
    "                                 .when(col(\"FAIXAETARIA\") == '1', '13-20')\n",
    "                                 .when(col(\"FAIXAETARIA\") == '2', '21-30')\n",
    "                                 .when(col(\"FAIXAETARIA\") == '3', '31-40')\n",
    "                                 .when(col(\"FAIXAETARIA\") == '4', '41-50')\n",
    "                                 .when(col(\"FAIXAETARIA\") == '5', '51-60')\n",
    "                                 .when(col(\"FAIXAETARIA\") == '6', '61-70')\n",
    "                                 .when(col(\"FAIXAETARIA\") == '7', '71-80')\n",
    "                                 .when(col(\"FAIXAETARIA\") == '8', '81+')\n",
    "                                 .otherwise('NÃO INFORMADO'))\n",
    "\n",
    "\n",
    "# Criar uma view temporária\n",
    "df_socios.createOrReplaceTempView(\"SOCIOS\")\n",
    "\n",
    "# Verificar os dados e esquema do DataFrame\n",
    "#df_socios.show()\n",
    "#df_socios.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a087bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código lê o arquivo CSV em um DataFrame Spark \n",
    "# e cria uma view temporária chamada \"SIMPLES\".\n",
    "\n",
    "file_path_simples = \"gs://dataproc-staging-us-central1-574457499229-8awbbdyx/notebooks/jupyter/DADOS/F.K03200$W.SIMPLES.CSV.D40608\"\n",
    "# Esquema para o arquivo SIMPLES\n",
    "schema_simples = StructType([\n",
    "    StructField(\"CNPJBASICO\", StringType(), True),\n",
    "    StructField(\"OPCAOPELOSIMPLES\", StringType(), True),\n",
    "    StructField(\"DATAOPCAOPELOSIMPLES\", StringType(), True),\n",
    "    StructField(\"DATAEXCLUSAODOSIMPLES\", StringType(), True),\n",
    "    StructField(\"OPCAOPELOMEI\", StringType(), True),\n",
    "    StructField(\"DATAOPCAOPELOMEI\", StringType(), True),\n",
    "    StructField(\"DATAEXCLUSAODOMEI\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Ler o arquivo CSV de SIMPLES em um DataFrame\n",
    "df_simples = spark.read.csv(file_path_simples, header=False, schema=schema_simples, sep=';')\n",
    "\n",
    "# Transformar campos de data\n",
    "df_simples = df_simples.withColumn(\"DATAOPCAOPELOSIMPLES\", to_date(df_simples[\"DATAOPCAOPELOSIMPLES\"], \"yyyyMMdd\"))\n",
    "df_simples = df_simples.withColumn(\"DATAEXCLUSAODOSIMPLES\", to_date(df_simples[\"DATAEXCLUSAODOSIMPLES\"], \"yyyyMMdd\"))\n",
    "df_simples = df_simples.withColumn(\"DATAOPCAOPELOMEI\", to_date(df_simples[\"DATAOPCAOPELOMEI\"], \"yyyyMMdd\"))\n",
    "df_simples = df_simples.withColumn(\"DATAEXCLUSAODOMEI\", to_date(df_simples[\"DATAEXCLUSAODOMEI\"], \"yyyyMMdd\"))\n",
    "# Traduzir valores 'S' e 'N' para 'SIM' e 'NÃO'\n",
    "df_simples = df_simples.withColumn(\"OPCAOPELOSIMPLES\", when(df_simples[\"OPCAOPELOSIMPLES\"] == 'S', 'SIM').otherwise('NÃO'))\n",
    "df_simples = df_simples.withColumn(\"OPCAOPELOMEI\", when(df_simples[\"OPCAOPELOMEI\"] == 'S', 'SIM').otherwise('NÃO'))\n",
    "\n",
    "\n",
    "\n",
    "# Criar uma view temporária\n",
    "df_simples.createOrReplaceTempView(\"SIMPLES\")\n",
    "\n",
    "# Verificar os dados e esquema do DataFrame\n",
    "#df_simples.show()\n",
    "#df_simples.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d0030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código carrega várias tabelas de domínio (CNAE, MOTI, MUNIC, NATJU, PAIS, QUALS)\n",
    "#a partir de arquivos CSV armazenados no Google Cloud Storage, \n",
    "#utilizando esquemas específicos e a codificação ISO-8859-1, e cria views temporárias no Spark para cada uma dessas tabelas.\n",
    "\n",
    "# CARREGANDO AS TABELAS DE DOMÍNIO\n",
    "file_paths_codigos = {\n",
    "    \"CNAE\": \"gs://dataproc-staging-us-central1-574457499229-8awbbdyx/notebooks/jupyter/DADOS/F.K03200$Z.D40608.CNAECSV\",\n",
    "    \"MOTI\": \"gs://dataproc-staging-us-central1-574457499229-8awbbdyx/notebooks/jupyter/DADOS/F.K03200$Z.D40608.MOTICSV\",\n",
    "    \"MUNIC\": \"gs://dataproc-staging-us-central1-574457499229-8awbbdyx/notebooks/jupyter/DADOS/F.K03200$Z.D40608.MUNICCSV\",\n",
    "    \"NATJU\": \"gs://dataproc-staging-us-central1-574457499229-8awbbdyx/notebooks/jupyter/DADOS/F.K03200$Z.D40608.NATJUCSV\",\n",
    "    \"PAIS\": \"gs://dataproc-staging-us-central1-574457499229-8awbbdyx/notebooks/jupyter/DADOS/F.K03200$Z.D40608.PAISCSV\",\n",
    "    \"QUALS\": \"gs://dataproc-staging-us-central1-574457499229-8awbbdyx/notebooks/jupyter/DADOS/F.K03200$Z.D40608.QUALSCSV\"\n",
    "}\n",
    "\n",
    "# Esquemas para os arquivos CSV das tabelas de códigos\n",
    "schemas_codigos = {\n",
    "    \"CNAE\": StructType([StructField(\"CNAE_CODIGO\", StringType(), True), StructField(\"CNAE_DESCRICAO\", StringType(), True)]),\n",
    "    \"MOTI\": StructType([StructField(\"MOTIVO_CODIGO\", StringType(), True), StructField(\"MOTIVO_DESCRICAO\", StringType(), True)]),\n",
    "    \"MUNIC\": StructType([StructField(\"MUNICIPIO_CODIGO\", StringType(), True), StructField(\"MUNICIPIO_DESCRICAO\", StringType(), True)]),\n",
    "    \"NATJU\": StructType([StructField(\"NATJU_CODIGO\", StringType(), True), StructField(\"NATJU_DESCRICAO\", StringType(), True)]),\n",
    "    \"PAIS\": StructType([StructField(\"PAIS_CODIGO\", StringType(), True), StructField(\"PAIS_DESCRICAO\", StringType(), True)]),\n",
    "    \"QUALS\": StructType([StructField(\"QUALS_CODIGO\", StringType(), True), StructField(\"QUALS_DESCRICAO\", StringType(), True)])\n",
    "}  \n",
    "    \n",
    "    # Função para carregar os DataFrames de códigos com especificação de codificação\n",
    "def load_codigos(file_path, schema, encoding=\"UTF-8\"):\n",
    "    return spark.read.csv(file_path, header=False, schema=schema, sep=';', encoding=encoding)\n",
    "\n",
    "# Carregar os DataFrames de códigos com especificação de codificação\n",
    "df_codigos = {key: load_codigos(file_paths_codigos[key], schemas_codigos[key], encoding=\"ISO-8859-1\") for key in file_paths_codigos}\n",
    "\n",
    "# Criar views temporárias para as tabelas de códigos\n",
    "for key, df in df_codigos.items():\n",
    "    df.createOrReplaceTempView(key)\n",
    "    \n",
    "#Como algumas consultas podem ter a descrição do CNAE em vez do numero, vamos criar essa tabela e usar para indexar os LLM\n",
    "    \n",
    "df_cnaes = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        c.CNAE_CODIGO,\n",
    "        c.CNAE_DESCRICAO\n",
    "    FROM CNAE c\n",
    "\"\"\")\n",
    "\n",
    "df_cnaes.cache()\n",
    "\n",
    "# Trigger an action to force caching\n",
    "df_cnaes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e7b5c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SUBSTITUINDO NA TABELA EMPRESAS OS CODIGOS PELAS DESCRIÇÕES DAS TABELAS DE DOMINIO\n",
    "# Substituir códigos pelas descrições nas tabelas EMPRESAS\n",
    "df_empresas_desc = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        e.CNPJBASICO,\n",
    "        e.RAZAOSOCIAL,\n",
    "        nj.NATJU_DESCRICAO as NATUREZAJURIDICA,\n",
    "        q.QUALS_DESCRICAO as QUALIFICACAODORESPONSAVEL,\n",
    "        e.CAPITALSOCIAL,\n",
    "        e.PORTE,\n",
    "        e.ENTEFEDERATIVO\n",
    "    FROM EMPRESAS e\n",
    "    LEFT JOIN NATJU nj ON e.NATUREZAJURIDICA = nj.NATJU_CODIGO\n",
    "    LEFT JOIN QUALS q ON e.QUALIFICACAODORESPONSAVEL = q.QUALS_CODIGO\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "df_empresas_desc.cache()\n",
    "\n",
    "# Trigger an action to force caching\n",
    "df_empresas_desc.count()\n",
    "\n",
    "# Create a view from the cached DataFrame\n",
    "df_empresas_desc.createOrReplaceTempView(\"EMPRESAS\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddc5eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir códigos pelas descrições nas tabelas ESTABELECIMENTOS\n",
    "df_estabele_desc = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        e.CNPJBASICO,\n",
    "        e.CNPJORDEM,\n",
    "        e.CNPJDV,\n",
    "        e.IDENTIFICADORMATRIZFILIAL,\n",
    "        e.NOMEFANTASIA,\n",
    "        e.SITUACAOCADASTRAL,\n",
    "        e.DATASITUACAOCADASTRAL,\n",
    "        m.MOTIVO_DESCRICAO as MOTIVOSITUACAOCADASTRAL,\n",
    "        e.NOMECIDADEEXTERIOR,\n",
    "        p.PAIS_DESCRICAO as PAIS,\n",
    "        e.DATAINICIOATIVIDADE,\n",
    "        c.CNAE_DESCRICAO as CNAEFISCALPRINCIPAL,\n",
    "        e.CNAEFISCALSECUNDARIA,\n",
    "        e.TIPOLOGRADOURO,\n",
    "        e.LOGRADOURO,\n",
    "        e.NUMERO,\n",
    "        e.COMPLEMENTO,\n",
    "        e.BAIRRO,\n",
    "        e.CEP,\n",
    "        e.UF,\n",
    "        mu.MUNICIPIO_DESCRICAO as MUNICIPIO,\n",
    "        e.DDD1,\n",
    "        e.TELEFONE1,\n",
    "        e.DDD2,\n",
    "        e.TELEFONE2,\n",
    "        e.DDDFAX,\n",
    "        e.FAX,\n",
    "        e.EMAIL,\n",
    "        e.SITUACAOESPECIAL,\n",
    "        e.DATASITUACAOESPECIAL\n",
    "    FROM ESTABELECIMENTOS e\n",
    "    LEFT JOIN MOTI m ON e.MOTIVOSITUACAOCADASTRAL = m.MOTIVO_CODIGO\n",
    "    LEFT JOIN PAIS p ON e.PAIS = p.PAIS_CODIGO\n",
    "    LEFT JOIN CNAE c ON e.CNAEFISCALPRINCIPAL = c.CNAE_CODIGO\n",
    "    LEFT JOIN MUNIC mu ON e.MUNICIPIO = mu.MUNICIPIO_CODIGO\n",
    "    wHERE CNPJBASICO != 13269396\n",
    "\"\"\")\n",
    "\n",
    "df_estabele_desc.cache()\n",
    "\n",
    "# Trigger an action to force caching\n",
    "df_estabele_desc.count()\n",
    "\n",
    "df_estabele_desc.createOrReplaceTempView(\"ESTABELECIMENTOS\")\n",
    "#df_estabele_desc.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49fc93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir códigos pelas descrições nas tabelas SOCIOS\n",
    "\n",
    "df_socios_desc = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        s.CNPJBASICO,\n",
    "        s.IDENTIFICADORSOCIO,\n",
    "        s.NOMESOCIORAZAOSOCIAL,\n",
    "        s.CNPJCPFSOCIO,\n",
    "        q.QUALS_DESCRICAO as QUALIFICACAOSOCIO,\n",
    "        s.DATAENTRADASOCIEDADE,\n",
    "        p.PAIS_DESCRICAO as PAIS,\n",
    "        s.CPFREPRESENTANTE,\n",
    "        s.NOMEREPRESENTANTE,\n",
    "        qr.QUALS_DESCRICAO as QUALIFICACAOREPRESENTANTE,\n",
    "        s.FAIXAETARIA\n",
    "    FROM SOCIOS s\n",
    "    LEFT JOIN QUALS q ON s.QUALIFICACAOSOCIO = q.QUALS_CODIGO\n",
    "    LEFT JOIN PAIS p ON s.PAIS = p.PAIS_CODIGO\n",
    "    LEFT JOIN QUALS qr ON s.QUALIFICACAOREPRESENTANTE = qr.QUALS_CODIGO\n",
    "\"\"\")\n",
    "\n",
    "# Atualizar a coluna \"PAIS\" para 'BRASIL' onde estiver nula ou vazia\n",
    "df_socios_desc = df_socios_desc.withColumn(\n",
    "    \"PAIS\", \n",
    "    when((col(\"PAIS\") == '') | col(\"PAIS\").isNull(), 'BRASIL')\n",
    "    .otherwise(col(\"PAIS\"))\n",
    ")\n",
    "\n",
    "# Criar uma view temporária\n",
    "df_socios.createOrReplaceTempView(\"SOCIOS\")\n",
    "\n",
    "\n",
    "df_socios_desc.cache()\n",
    "\n",
    "# Trigger an action to force caching\n",
    "df_socios_desc.count()\n",
    "\n",
    "df_socios_desc.createOrReplaceTempView(\"SOCIOS\")\n",
    "#df_socios_desc.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ffd0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Função para obter detalhes da view\n",
    "def get_view_details(view_name):\n",
    "    df = spark.sql(f\"SELECT * FROM {view_name}\")\n",
    "    num_rows = df.count()\n",
    "    num_columns = len(df.columns)\n",
    "    schema = df._jdf.schema().treeString()  # Obter o schema formatado com quebras de linha\n",
    "    return (view_name, num_rows, num_columns, schema)\n",
    "\n",
    "# Obter detalhes de cada view\n",
    "views = [\"EMPRESAS\", \"ESTABELECIMENTOS\", \"SOCIOS\", \"SIMPLES\",\"CNAE\"]\n",
    "details = [get_view_details(view) for view in views]\n",
    "\n",
    "# Criar DataFrame com os detalhes\n",
    "df_details = pd.DataFrame(details, columns=[\"View\", \"Number of Rows\", \"Number of Columns\", \"Schema\"])\n",
    "\n",
    "# Exibir a tabela com schemas formatados\n",
    "for index, row in df_details.iterrows():\n",
    "    print(f\"View: {row['View']}\")\n",
    "    print(f\"Number of Rows: {row['Number of Rows']}\")\n",
    "    print(f\"Number of Columns: {row['Number of Columns']}\")\n",
    "    print(f\"Schema:\\n{row['Schema']}\\n\")\n",
    "\n",
    "# Calcular e imprimir a quantidade total de linhas\n",
    "total_rows = df_details[\"Number of Rows\"].sum()\n",
    "print(f\"\\nTotal Number of Rows: {total_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd5f6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar a view EMPRESAS como CSV\n",
    "df_empresas = spark.sql(\"SELECT * FROM EMPRESAS\")\n",
    "df_empresas.coalesce(1).write.csv(\"gs://dataproc-staging-us-central1-574457499229-8awbbdyx/notebooks/jupyter/DADOS/DadosProcessados/empresas.csv\", header=True, sep=\";\", mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a65937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando os arquivos como CSV para poder importar localmente\n",
    "# Salvar a view ESTABELECIMENTOS como CSV\n",
    "df_estabelecimentos = spark.sql(\"SELECT * FROM ESTABELECIMENTOS WHERE CNPJBASICO != 13269396\")\n",
    "df_estabelecimentos.coalesce(1).write.csv(\"gs://dataproc-staging-us-central1-574457499229-8awbbdyx/notebooks/jupyter/DADOS/DadosProcessados/estabelecimentos.csv\", header=True, sep=\";\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029aab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar a view SOCIOS como CSV\n",
    "df_socios = spark.sql(\"SELECT * FROM SOCIOS\")\n",
    "df_socios.coalesce(1).write.csv(\"gs://dataproc-staging-us-central1-574457499229-8awbbdyx/notebooks/jupyter/DADOS/DadosProcessados/socios.csv\", header=True, sep=\";\", mode=\"overwrite\")\n",
    "\n",
    "# Salvar a view SIMPLES como CSV\n",
    "df_simples = spark.sql(\"SELECT * FROM SIMPLES\")\n",
    "df_simples.coalesce(1).write.csv(\"gs://dataproc-staging-us-central1-574457499229-8awbbdyx/notebooks/jupyter/DADOS/DadosProcessados/simples.csv\", header=True, sep=\";\", mode=\"overwrite\")\n",
    "\n",
    "# Salvar a view CNAE como CSV\n",
    "df_cnaes.coalesce(1).write.csv(\"gs://dataproc-staging-us-central1-574457499229-8awbbdyx/notebooks/jupyter/DADOS/DadosProcessados/cnaes.csv\", header=True, sep=\";\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3109be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para parar a sessão do Spark\n",
    "def stop_spark_session(spark_session_name):\n",
    "    # Verificar se a sessão existe e pará-la\n",
    "    if spark_session_name in locals():\n",
    "        locals()[spark_session_name].stop()\n",
    "        print(f\"Sessão {spark_session_name} parada.\")\n",
    "\n",
    "stop_spark_session('CNPJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca6a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_spark_session('CNPJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30a95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar a view SIMPLES como CSV\n",
    "df_simples = spark.sql(\"SELECT * FROM SIMPLES\")\n",
    "df_simples.coalesce(1).write.csv(\"gs://dataproc-staging-us-central1-574457499229-8awbbdyx/notebooks/jupyter/DADOS/DadosProcessados/simples.csv\", header=True, sep=\";\", mode=\"overwrite\")\n",
    "\n",
    "# Salvar a view CNAE como CSV\n",
    "df_cnaes.coalesce(1).write.csv(\"gs://dataproc-staging-us-central1-574457499229-8awbbdyx/notebooks/jupyter/DADOS/DadosProcessados/cnaes.csv\", header=True, sep=\";\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c16d7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
